{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9140ceaa-9ea6-4a0e-827c-a9e250cee60a",
   "metadata": {},
   "source": [
    "## Natural Language Processing Analysis of State's Curricula in Brazil\n",
    "\n",
    "### Step 01 : Text Wrangling\n",
    "\n",
    "Cleanning the data: \n",
    "\n",
    "Tokenizing\n",
    "Tagger\n",
    "Parser\n",
    "Ner\n",
    "\n",
    "Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159f6a18-59ca-42c6-8e40-8ca680dc0f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d21cfcc-dcd3-4a73-ae7c-75ecf3a6fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Francisco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Francisco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Francisco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Francisco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Francisco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a33bdaa-7c10-400d-af8c-5c774c73b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "lang = 'pt'\n",
    "pipeline = [\"tok2vec\", \"tagger\", \"parser\", \"lemmatizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "530ae8e3-f2f3-4f74-bd89-9354b59195e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup in Brazilian Portuguese\n",
    "\n",
    "import pt_core_news_sm\n",
    "nlp = pt_core_news_sm.load()\n",
    "path = r'C:\\Users\\Francisco\\Desktop\\Python\\FinalPaper\\Analysis\\\\*.txt'\n",
    "nlp.max_length = 15384682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb87c409-86ec-4ef6-8fc5-260125b39387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting .txt as a Corpus\n",
    "\n",
    "AM = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\AM.txt', encoding = 'utf-8').read()\n",
    "DF = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\DF.txt', encoding = 'utf-8').read()\n",
    "GO = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\GO.txt', encoding = 'utf-8').read()\n",
    "MG = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\MG.txt', encoding = 'utf-8').read()\n",
    "MT = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\MG.txt', encoding = 'utf-8').read()\n",
    "PA = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\PA.txt', encoding = 'utf-8').read()\n",
    "PE = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\PE.txt', encoding = 'utf-8').read()\n",
    "SC = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\SC.txt', encoding = 'utf-8').read()\n",
    "SP = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\SP.txt', encoding = 'utf-8').read()\n",
    "BNCC = open(r'C:\\\\Users\\\\Francisco\\\\Desktop\\\\Python\\\\FinalPaper\\\\Analysis\\\\BNCC.txt', encoding = 'utf-8').read()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24652670-20f9-4ef8-904c-9fd57831b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = MG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0819ea2-a902-43fc-b90c-5b410751aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc1 = list(nlp.pipe(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f311449b-7e4d-4fa2-be6c-3ed9f431fb67",
   "metadata": {},
   "source": [
    "Next chunk will have spaCy apply its entire NLP \"pipeline\" to the text as soon as it is provided to the model and outputs a processed \"doc.\"\n",
    "\n",
    "<img src=\"https://d33wubrfki0l68.cloudfront.net/3ad0582d97663a1272ffc4ccf09f1c5b335b17e9/7f49c/pipeline-fde48da9b43661abcdf62ab70a546d71.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8affc6-c942-42b7-8d54-48fef6cb011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have the choice of applying pipeline to Corpus at the same time\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "930e683f-ec6a-435e-ba50-a1fdb4ecf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = list(nlp.pipe(MG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b329ea-3b5d-4f71-8b08-bebd3a7d67ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "﻿CURRÍCULO\n",
       "CURRÍCULO REFERÊNCIA DE MINAS GERAIS\n",
       "Currículo Referência de Minas Gerais\n",
       "Lista de Figuras\n",
       "Figura 1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "458ef3b7-6c1f-4e3a-8f42-8b75b93969e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words Object\n",
    "\n",
    "words = [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6bd1ca4-f236-4c9b-9df9-f2e02d788054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences Object\n",
    "\n",
    "sentences = [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a71ce-bf01-4577-9a76-7fb0c27ae822",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93430a59-34a6-458d-9f57-fface8a5ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation and Spaces\n",
    "no_punct_or_space = [token for token in doc if token.is_punct == False and token.is_space == False]\n",
    "\n",
    "# Remove Numbers and lower case everything\n",
    "lower_alpha = [token.lower_ for token in no_punct_or_space if token.is_alpha == True]\n",
    "\n",
    "# Remove Custom Stop Words (if needed)\n",
    "\n",
    "#custom_stopwords = [\"distrito\", \"federal\"]\n",
    "#custom_clean = [token for token in clean if token not in custom_stopwords]\n",
    "#custom_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82cea8fa-779b-4662-8396-ed6e7d4ec2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaned Corpus\n",
    "\n",
    "clean = [token.lower_ for token in no_punct_or_space if token.is_alpha == True and token.is_stop == False]\n",
    "clean[:30]\n",
    "type(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d38d3-cf5f-41fb-a067-b53f1ea9d112",
   "metadata": {},
   "source": [
    "## Part-of-speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b42f69-7cb6-45e1-83d8-68259448d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [token for token in doc if token.pos_ == \"NOUN\"]\n",
    "verbs = [token for token in doc if token.pos_ == \"VERB\"]\n",
    "proper_nouns = [token for token in doc if token.pos_ == \"PROPN\"]\n",
    "adjectives = [token for token in doc if token.pos_ == \"ADJ\"]\n",
    "adverbs = [token for token in doc if token.pos_ == \"ADV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7471247-74d3-4d7d-850f-939126fa6b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nouns': 49768,\n",
       " 'verbs': 16401,\n",
       " 'proper_nouns': 18582,\n",
       " 'adjectives': 16578,\n",
       " 'adverbs': 4250}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counts = {\n",
    "    \"nouns\": len(nouns),\n",
    "    \"verbs\": len(verbs),\n",
    "    \"proper_nouns\": len(proper_nouns),\n",
    "    \"adjectives\": len(adjectives),\n",
    "    \"adverbs\": len(adverbs) \n",
    "}\n",
    "\n",
    "pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d333ded4-4501-4cf9-8c5b-e926b73dbfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abb95d-67f2-41c5-a286-c6bed01a71a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84b0f83a-9a21-4575-b70f-e84a1190d344",
   "metadata": {},
   "source": [
    "## Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48b176af-c942-46db-9743-7e4b55bc5613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in document:  220689\n",
      "Number of tokens in cleaned document:  95357\n",
      "Number of unique tokens in cleaned document:  10792\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens in document: \", len(doc))\n",
    "print(\"Number of tokens in cleaned document: \", len(clean))\n",
    "print(\"Number of unique tokens in cleaned document: \", len(set(clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c14c7aa3-9759-4e6b-9498-8ffcf47fe90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('educação', 1329),\n",
       " ('ensino', 838),\n",
       " ('currículo', 830),\n",
       " ('gerais', 784),\n",
       " ('minas', 710),\n",
       " ('referência', 686),\n",
       " ('estudantes', 618),\n",
       " ('vida', 537),\n",
       " ('diferentes', 520),\n",
       " ('formação', 472),\n",
       " ('conhecimento', 445),\n",
       " ('sociais', 424),\n",
       " ('trabalho', 422),\n",
       " ('desenvolvimento', 394),\n",
       " ('habilidades', 386),\n",
       " ('práticas', 386),\n",
       " ('social', 354),\n",
       " ('médio', 353),\n",
       " ('mundo', 335),\n",
       " ('processo', 311),\n",
       " ('análise', 302),\n",
       " ('estudante', 302),\n",
       " ('produção', 300),\n",
       " ('tecnologias', 295),\n",
       " ('brasil', 281),\n",
       " ('processos', 279),\n",
       " ('conhecimentos', 279),\n",
       " ('nacional', 277),\n",
       " ('linguagens', 265),\n",
       " ('escola', 254),\n",
       " ('profissional', 252),\n",
       " ('campo', 250),\n",
       " ('aprendizagem', 248),\n",
       " ('lei', 241),\n",
       " ('textos', 240),\n",
       " ('culturais', 238),\n",
       " ('básica', 234),\n",
       " ('construção', 233),\n",
       " ('bncc', 227),\n",
       " ('escolar', 227),\n",
       " ('competências', 224),\n",
       " ('ciências', 224),\n",
       " ('sociedade', 224),\n",
       " ('acesso', 220),\n",
       " ('relações', 219),\n",
       " ('curricular', 218),\n",
       " ('curriculares', 214),\n",
       " ('contexto', 211),\n",
       " ('n', 210),\n",
       " ('natureza', 202),\n",
       " ('uso', 201),\n",
       " ('problemas', 196),\n",
       " ('projeto', 195),\n",
       " ('jovens', 191),\n",
       " ('diretrizes', 184),\n",
       " ('compreensão', 183),\n",
       " ('língua', 183),\n",
       " ('itinerários', 182),\n",
       " ('modo', 181),\n",
       " ('atividades', 177),\n",
       " ('diversas', 176),\n",
       " ('física', 175),\n",
       " ('arte', 174),\n",
       " ('áreas', 170),\n",
       " ('realidade', 170),\n",
       " ('matemática', 167),\n",
       " ('ações', 166),\n",
       " ('sentido', 166),\n",
       " ('formas', 163),\n",
       " ('formativos', 160),\n",
       " ('analisar', 159),\n",
       " ('história', 159),\n",
       " ('contextos', 157),\n",
       " ('organização', 156),\n",
       " ('artísticas', 156),\n",
       " ('cultura', 155),\n",
       " ('escolas', 152),\n",
       " ('projetos', 150),\n",
       " ('digitais', 150),\n",
       " ('fundamental', 148),\n",
       " ('política', 148),\n",
       " ('estratégias', 148),\n",
       " ('resolução', 148),\n",
       " ('diversidade', 145),\n",
       " ('direitos', 145),\n",
       " ('ambiente', 144),\n",
       " ('recursos', 143),\n",
       " ('componente', 142),\n",
       " ('professores', 141),\n",
       " ('cultural', 141),\n",
       " ('competência', 140),\n",
       " ('disponível', 140),\n",
       " ('ambiental', 138),\n",
       " ('valores', 138),\n",
       " ('componentes', 138),\n",
       " ('questões', 137),\n",
       " ('avaliação', 137),\n",
       " ('movimento', 137),\n",
       " ('importante', 137),\n",
       " ('saúde', 136)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cleaned_counter = Counter(clean)\n",
    "cleaned_counter.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173199b9-3549-46c1-a402-088fda5db653",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "751279e3-9696-4acb-bb7a-6086f855838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1da7a89d-fd6c-465b-95e0-946ed298a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [d.split() for d in clean]\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39e6b237-bd58-4a8c-8522-b9b1080cd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=29, random_state=100,\n",
    "                chunksize=1000, passes=100,iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f5b27ac-ad59-4a44-9e06-3ee85b725dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (23,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (14,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (3,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (26,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (24,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (15,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (4,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (19,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (20,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (17,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (28,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (8,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (2,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (21,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (9,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (18,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (27,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (11,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"'),\n",
       " (12,\n",
       "  '0.000*\"chamar\" + 0.000*\"incessantes\" + 0.000*\"carta\" + 0.000*\"ameneceu\" + 0.000*\"concluímos\" + 0.000*\"acontece\" + 0.000*\"comportar\" + 0.000*\"precisamente\" + 0.000*\"ocupa\" + 0.000*\"epicuro\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89b719f8-b927-428c-8b60-2175de01ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_per_topic = []\n",
    "for t in range(lda_model.num_topics):\n",
    "    top_words_per_topic.extend([(t, ) + x for x in lda_model.show_topic(t, topn = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7939d93c-8224-4249-b442-629860d86728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(top_words_per_topic, columns=['Topic', 'Word', 'P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb46e6fe-bce1-480b-96c7-2d549849e2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Word</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>acontece</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>concluímos</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>precisamente</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>comportar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>chamar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>acontece</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>concluímos</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>precisamente</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>comportar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>chamar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>acontece</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>concluímos</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>precisamente</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>comportar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>chamar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>acontece</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>concluímos</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>precisamente</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>comportar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>chamar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>acontece</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>concluímos</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>precisamente</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>comportar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>chamar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>acontece</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>concluímos</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>precisamente</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>comportar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>chamar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>acontece</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>concluímos</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>precisamente</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>comportar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>chamar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7</td>\n",
       "      <td>acontece</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7</td>\n",
       "      <td>concluímos</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7</td>\n",
       "      <td>precisamente</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7</td>\n",
       "      <td>comportar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7</td>\n",
       "      <td>chamar</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic          Word         P\n",
       "0       0      acontece  0.000093\n",
       "1       0    concluímos  0.000093\n",
       "2       0  precisamente  0.000093\n",
       "3       0     comportar  0.000093\n",
       "4       0        chamar  0.000093\n",
       "5       1      acontece  0.000093\n",
       "6       1    concluímos  0.000093\n",
       "7       1  precisamente  0.000093\n",
       "8       1     comportar  0.000093\n",
       "9       1        chamar  0.000093\n",
       "10      2      acontece  0.000093\n",
       "11      2    concluímos  0.000093\n",
       "12      2  precisamente  0.000093\n",
       "13      2     comportar  0.000093\n",
       "14      2        chamar  0.000093\n",
       "15      3      acontece  0.000093\n",
       "16      3    concluímos  0.000093\n",
       "17      3  precisamente  0.000093\n",
       "18      3     comportar  0.000093\n",
       "19      3        chamar  0.000093\n",
       "20      4      acontece  0.000093\n",
       "21      4    concluímos  0.000093\n",
       "22      4  precisamente  0.000093\n",
       "23      4     comportar  0.000093\n",
       "24      4        chamar  0.000093\n",
       "25      5      acontece  0.000093\n",
       "26      5    concluímos  0.000093\n",
       "27      5  precisamente  0.000093\n",
       "28      5     comportar  0.000093\n",
       "29      5        chamar  0.000093\n",
       "30      6      acontece  0.000093\n",
       "31      6    concluímos  0.000093\n",
       "32      6  precisamente  0.000093\n",
       "33      6     comportar  0.000093\n",
       "34      6        chamar  0.000093\n",
       "35      7      acontece  0.000093\n",
       "36      7    concluímos  0.000093\n",
       "37      7  precisamente  0.000093\n",
       "38      7     comportar  0.000093\n",
       "39      7        chamar  0.000093"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af3872c8-9dd6-4d93-882e-835655edc010",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\FRANCI~1\\AppData\\Local\\Temp/ipykernel_10792/3791860902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Word\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"P\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\regression.py\u001b[0m in \u001b[0;36mregplot\u001b[1;34m(x, y, data, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, seed, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, label, color, marker, scatter_kws, line_kws, ax)\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[0mscatter_kws\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"marker\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[0mline_kws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mline_kws\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_kws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m     \u001b[0mplotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscatter_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_kws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\regression.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, ax, scatter_kws, line_kws)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_reg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_kws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;31m# Label the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\regression.py\u001b[0m in \u001b[0;36mlineplot\u001b[1;34m(self, ax, kws)\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;34m\"\"\"Draw the model.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;31m# Fit the regression model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m         \u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_bands\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m         \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\regression.py\u001b[0m in \u001b[0;36mfit_regression\u001b[1;34m(self, ax, x_range, grid)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                     \u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[0mci\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mci\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;31m# Convert float/complex array scalars to float, gh-3504\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;31m# and make sure one can use variables that have an __array_interface__, gh-6634\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m     \u001b[0mstop\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> dtype('<U32')"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUUElEQVR4nO3df7AlZX3n8fdHRgXklw5DaiWMY1yiGFYIXolGGUlkNbJWEEJ+GIxiDCy1LEq2NG62sm4SExd0TVnqIrKKYxKXpBTWBFCUQn6s4rjeUQYGMcICUZRaRmE1SMow8N0/+rnL8Xhn7jlz7+XOPLxfVbdOn+6nu7/93O7P6dPn3NupKiRJfXncShcgSVp6hrskdchwl6QOGe6S1CHDXZI6ZLhLUodWNNyTXJjkniRblmh5DyW5of387VIsU5J2R1nJ77knWQ/cD/x5VR2+BMu7v6r2WXxlkrR7W9Ez96q6Drh3dFySZyS5IsmmJP8zybNWqDxJ2m3titfcLwDOqqrnAm8Czpti3j2TzCbZmOSVy1KdJO0GVq10AaOS7AP8PPCxJHOjn9imnQT88TyzfauqXtaG11bVt5P8FPDZJDdV1f9e7rolaVezS4U7wzuJ/1tVR45PqKpLgEt2NHNVfbs93p7kGuBnAcNd0mPOLnVZpqq+D9yR5FcBMjhiknmTPDnJ3Fn+gcALga8uW7GStAtb6a9CXgR8AXhmkruSvB44BXh9ks3AzcAJEy7uMGC2zXc1cE5VGe6SHpNW9KuQkqTlsUtdlpEkLY0V+0D1wAMPrHXr1q3U6iVpt7Rp06bvVNWahdqtWLivW7eO2dnZlVq9JO2Wkvz9JO28LCNJHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR2aKNyTvDHJliQ3Jzl7O22OTXJDa3PtklYpSZrKqoUaJDkcOA04Gvgn4Iokl1fVrSNtDgDOA36pqr6R5KBlqleSNIFJztwPAzZW1QNVtQ24FjhxrM1vApdU1TcAquqepS1TkjSNScJ9C7A+yeokewPHA4eMtflp4MlJrkmyKclr5ltQktOTzCaZ3bp16+IqlyRt14KXZarqliTnAlcC9wObgW3zLOe5wEuAvYAvJNlYVV8fW9YFwAUAMzMztfjyJUnzmegD1ar6UFUdVVXrgXuBW8ea3AVcUVU/qKrvANcBRyxtqZKkSU36bZmD2uNa4CTgorEmfwMck2RVu3Tzc8AtS1moJGlyC16WaS5Oshp4EDizqu5LcgZAVZ3fLt1cAdwIPAx8sKq2LE/JkqSFTBTuVXXMPOPOH3v+TuCdS1SXJGkR/AtVSeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0EThnuSNSbYkuTnJ2Tto97wkDyU5eckqlCRNbcFwT3I4cBpwNHAE8Iokh87Tbg/gXODTS12kJGk6k5y5HwZsrKoHqmobcC1w4jztzgIuBu5ZwvokSTthknDfAqxPsjrJ3sDxwCGjDZIczBD45y99iZKkaa1aqEFV3ZLkXOBK4H5gM7BtrNm7gbdU1UNJtrusJKcDpwOsXbt2J0uWJC0kVTXdDMnbgbuq6ryRcXcAc6l+IPAAcHpVfWJ7y5mZmanZ2dmpC5akx7Ikm6pqZqF2C565t4UdVFX3JFkLnAS8YHR6VT19pO0G4LIdBbskaXlNFO7AxUlWAw8CZ1bVfUnOAKgqr7NL0i5monCvqmPmGTdvqFfVqYusSZK0SP6FqiR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOjTRDbJ3Fev+/eU/Nu7Oc/7VClSy+7DPpmN/Tcf+ms6j2V+7zZn7fJ2yo/Gyz6Zlf03H/prOo91fu024S5ImZ7hLUocMd0nqkOEuSR3abcJ9e58o+8n89tln07G/pmN/TefR7q9U1bIseCEzMzM1Ozu7IuuWpN1Vkk1VNbNQu93mzF2SNDnDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQxOFe5I3JtmS5OYkZ88z/ZQkN7af65McseSVSpImtmC4JzkcOA04GjgCeEWSQ8ea3QG8uKqeA7wNuGCpC5UkTW6SM/fDgI1V9UBVbQOuBU4cbVBV11fVfe3pRuAnl7ZMSdI0Jgn3LcD6JKuT7A0cDxyyg/avBz4134QkpyeZTTK7devW6auVJE1kwTsxVdUtSc4FrgTuBzYD2+Zrm+QXGML9RdtZ1gW0SzYzMzMr838PJOkxYKIPVKvqQ1V1VFWtB+4Fbh1vk+Q5wAeBE6rqu0tbpiRpGhPdQzXJQVV1T5K1wEnAC8amrwUuAX6rqr6+9GVKkqYx6Q2yL06yGngQOLOq7ktyBkBVnQ+8FVgNnJcEYNsk/7VMkrQ8Jgr3qjpmnnHnjwz/DvA7S1iXJGkR/AtVSeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR2aKNyTvDHJliQ3Jzl7nulJ8p4ktyW5MclRS16pJGliC4Z7ksOB04CjgSOAVyQ5dKzZy4FD28/pwPuXuE5J0hQmOXM/DNhYVQ9U1TbgWuDEsTYnAH9eg43AAUn+2RLXKkma0CThvgVYn2R1kr2B44FDxtocDHxz5PldbdyPSHJ6ktkks1u3bt3ZmiVJC1gw3KvqFuBc4ErgCmAzsG2sWeabdZ5lXVBVM1U1s2bNmp0oV5I0iYk+UK2qD1XVUVW1HrgXuHWsyV386Nn8TwLfXpoSJUnTmvTbMge1x7XAScBFY03+FnhN+9bM84HvVdXdS1qpJGliqyZsd3GS1cCDwJlVdV+SMwCq6nzgkwzX4m8DHgBetxzFSpImM1G4V9Ux84w7f2S4gDOXsC5J0iL4F6qS1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktShicI9ye8muTnJliQXJdlzbPr+SS5Nsrm1e93ylCtJmsSC4Z7kYOANwExVHQ7sAfzGWLMzga9W1RHAscC7kjxhiWuVJE1o0ssyq4C9kqwC9ga+PTa9gH2TBNgHuBfYtmRVSpKmsmC4V9W3gP8CfAO4G/heVX1mrNn7gMMYQv8m4I1V9fAS1ypJmtAkl2WeDJwAPB14KvCkJK8ea/Yy4IY2/UjgfUn2m2dZpyeZTTK7devWRZYuSdqeSS7LHAfcUVVbq+pB4BLg58favA64pAa3AXcAzxpfUFVdUFUzVTWzZs2axdYuSdqOScL9G8Dzk+zdrqm/BLhlnjYvAUjyE8AzgduXslBJ0uRWLdSgqr6Y5OPAlxk+JP0KcEGSM9r084G3ARuS3AQEeEtVfWf5ypYk7UiqakVWPDMzU7OzsyuybknaXSXZVFUzC7XzL1QlqUOGuyR1yHCXpA4Z7pLUoRX7QDXJVuDvd3L2AwG/jTMd+2w69td07K/pLKa/nlZVC/6h0IqF+2IkmZ3k02I9wj6bjv01HftrOo9Gf3lZRpI6ZLhLUod213C/YKUL2A3ZZ9Oxv6Zjf01n2ftrt7zmLknasd31zF2StAOG+2NYkiOTvHyl65C09HbbcE9yQJJ/s9J17IqSbEhy8gJt9gHeBWx6dKpaOUlmkrxnpesYleQ/rHQNKyXJK5M8e6XrWAqTHGsrZbcNd+AAwHDfeT8DnF1V96x0IdNKssc07atqtqresFz17KTHZLi3+zC/Epgq3Nt8GrFQnyx7uCf5RJJNSW5Ocnob90tJvpxkc5Kr2rintLY3JtmY5Dlt/B8muTDJNUluTzJ3kJ4DPCPJDUne2dq+OcmX2jL+aKSG17Rxm5P8RRu3JsnFrf2Xkrxwufti3HhdSZ6W5Ko27qoka1u7DUnek+T61gcnjyzj95Lc1JZxzjzruDPJgW14Jsk1bdJhwL8eWf77k1zdlv/i1ue3JNkwsqxXtXVtSXJuG7dHm39Lm/a7i+yTdUm+luQjrR8+3m4Uc2eStyb5HPCrSV6a5AttP/pYeydCkue1ftqc5H8l2TfJsUkua9Nf3PaZG5J8pU3fp/X3l9s2nDBWywfb9n00yXFJPp/k1iRHt3ZPav31pbbMuflPTXJJkita+3e08ecw3HD+hiQfbeNe3eq9IckHMuUL2AJ9Os1+Nsl+cH+Sd7X+uirJmjb+yAzH7o1J/keGW3SS4dh9e5JrgbcAvwy8s23rM5Kc1vpuc4Zjcu+Rev4sydXAuUvVH4sx3pdt9PqMHZtLsE8d3Zb5lfb4zDb+1La/XwqM38v6R1XVsv4AT2mPewFbgJ8Avgk8fWz6e4H/1IZ/EbihDf8hcD3wRIY/2f0u8HhgHbBlZD0vZfh6URhetC4D1jOcof4dcODY+v478KI2vBa4Zbn7Yqxffqwu4FLgte35bwOfaMMbgI+17Xo2cFsb//LWN3uPbdsG4OQ2fOfIOmaAa9rwqcD7Rtr/Veu7E4DvA/+irW8Tw31xn8pwx601DDd5+SzDGdhzgStHtuuARfbLOqCAF7bnFwJvatvxe23cgcB1wJPa87cAbwWewHAHsOe18fu1Wo8FLmvjLh1Z9j5t+ipgv5Fl39b6Yh3DDWpG++LCkX6a+/28HXj13PYDXwee1Pr4dmB/YE+Gf7dxSGt3/8g2H9bqenx7fh7wmhXaz3a4H7R2BZzSht86sh/dCLy4Df8x8O42fA1w3khNG2j7Z3u+emT4T4CzRtpdBuzxaB6bU/blBuY/Nhe7T+0HrGrDxwEXjxy3d9GO9R39PBpvdd6Q5MQ2fAhwOnBdVd0BUFX3tmkvAn6ljftsktVJ9m/TLq+qHwI/THIPwwvEuJe2n6+05/sAhwJHAB+vdmeokfUdBzw7ydz8+yXZt6r+YdFbPJlfHK8ryQuAk9r0vwDeMdL+E1X1MPDVDLcyhGEbPlxVD8wtYxH1XFpVleFuWv+nqm4CSHIzww75NIYXhq1t/EcZXjzfBvxUkvcCl7PQ2cRkvllVn2/DfwnMvVv76/b4fIYD6fPt9/cE4AsMt3e8u6q+BFBV32+1ji7788Cftfovqaq7kjweeHuS9cDDwME8so/dMdYXV43007rW5qXALyd5U3u+J8MJA63999r8X2Xox2+Obe9LGF4kv9Rq3QtYqstl0+5nC+0HNzD00dzv4i+BS9qxekBVXdvGf4Qh9Ob8Ndt3eJI/YXhh3Af49Mi0j1XVQ5Nv7rKary9h/mMzLG6f2h/4SJJDGV5MHz9Sx5WTHOvLGu5JjmUIoBdU1QMZLglsZjgIf6z5POPmvoT/w5FxDzF/3QH+c1V9YKyGN4wsZ9TjWl3/uINNWE5h/rpGjU4f7YOMPC60jG08cvltzx20m1v+w2Prepihv7fNW2DVfUmOAF4GnAn8GsPZ4GKMb9Pc8x+0xzDs4K8abZThUt4O+6OqzklyOXA8sDHJcQwvFmuA51bVg0nu5JG+Gu+L0X6a2w8D/EpV/d1YPT/H5PvuR6rq93dU+07a2f1se/vBQvNvzw92MG0D8Mqq2pzkVIZ3WpPM92jbXl/Od2yewuL2qbcBV1fViUnWMbz7mTNRnyz3Nff9gftasD+L4SB6IvDiJE+H4Vp7a3sdQ4fMvSh8Z+7Mazv+Adh35Pmngd/OI9deD05yEHAV8GtJVo+t7zPAv52bOcmRO7+ZO2W+uq4HfqNNPwX43ALL+AzDNs9do3zKPG3uZDgrhPbOaCd9keH3dmCG68GvAq7NcD3/cVV1MfAfgaMWsY45a9vZJW094/2wEXhhkn8OkOGa/E8DXwOemuR5bfy+GfvQKckzquqmqjoXmAWexbCf3tMOwl9gOLuexqeBs9JO45L87ATzPNjeMcCwL5zc9te5z5+mrWF7lmI/G/c4YO5zn98EPtfendyX5Jg2/reAa+ebmR8/dvcF7m79ccqUtTyatpcl81nsPrU/8K02fOq0hcIyn7kDVwBnJLmR4VrVRmArw6WZS5I8juHt579kuLb+4db2AeC1O1pwVX23fQixBfhUVb05yWHAF9oxdj/DddCbk/wpQxA9xHDZ5lSGt/r/ta1vFcOLyxlLuvU7rn++ut4AXJjkzQz99LoFlnFFe1GaTfJPwCf58W9h/BHwoQxfvfviIuq9O8nvA1cznJ18sqr+pp21f7j9LgGW4uzzFuC1ST4A3Aq8HzhrpJat7QzvoiRPbKP/oKq+nuTXgfcm2Qv4R4Z3jqPObgfbQ8BXgU8xhMulSWYZLjt8bcp63wa8G7ixBfydwCsWmOeC1v7LVXVKkj8APtP68UGGd0E7+y+x/7+l2M/m8QPgZ5JsAr4H/Hob/1rg/HaycfsOlvtXwH9r76pPZjgp+CLD9t7Ejwb/LmM7fbk9H2Vx+9Q7GC7L/DuGz7em5r8f0C6lvQW9rKoOX+laNL8k91fVPitdh3Zsd/6euyRpOzxzl6QOeeYuSR0y3CWpQ4a7JHXIcJekDhnuktSh/wezndDbuS0shwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=df[\"Word\"], y=df[\"P\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76c38754-0be5-4456-a580-2ead6041d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -61.01722717285156\n",
      "\n",
      "Coherence Score:  0.8710023468860444\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(doc_term_matrix,total_docs=10000))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus, dictionary=dictionary , coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53d9b042-dce1-4085-985e-63fd4e6875d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b551ae3-8eb8-438e-a12b-bc3143c15e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=doc_term_matrix, texts=corpus, start=2, limit=50, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a534d5-16f3-44f3-addc-9ab983562036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Show graph\n",
    "limit=50; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()# Print the coherence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f353db9-db30-420e-945c-4fd8d5844d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
